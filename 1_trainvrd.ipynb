{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_trainvrd.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNqT2dCn5vkX/34TDVnSTFs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Me5nmUjggaZg","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","import tensorflow as tf\n","import numpy as np\n","from model.config import cfg\n","from model.ass_fun import *\n","import tensorflow as tf\n","import tensorflow.contrib.slim as slim\n","from tensorflow.contrib.slim import losses\n","from tensorflow.contrib.slim import arg_scope\n","from tensorflow.contrib.slim import losses\n","from tensorflow.contrib.slim import arg_scope\n","from tensorflow.contrib.slim.python.slim.nets import resnet_utils\n","from tensorflow.contrib.slim.python.slim.nets import resnet_v1\n","from tensorflow.contrib.slim.python.slim.nets.resnet_v1 import resnet_v1_block\n","import os\n","import os.path as osp\n","import numpy as np\n","# `pip install easydict` if you don't have it\n","from easydict import EasyDict as edict\n","#______________________________________________\n","\n","__C = edict()\n","\n","cfg = __C\n","\n","__C.DIR = 'D:/Semnan Uni/Visual Relationships/New folder/vrd-master'\n","\n","__C.DIR2 = '/home/jhmei/yangxu/'\n","\n","__C.POOLING_SIZE = 7\n","\n","#VG\n","############################\n","__C.VG_BATCH_NUM = 128\n","__C.VG_BATCH_NUM2 = 30\n","__C.VG_NUM_CLASS = 201\n","__C.VG_NUM_RELA = 100\n","__C.VG_LR_INIT = 0.00001\n","__C.VG_TRAIN_ROUND = 30\n","__C.VG_RBM_SPARSITY_LAMBDA = 0.001\n","\n","__C.VG_BATCH_NUM_RELA = 128\n","__C.VG_AU_PAIR = 5\n","__C.VG_IOU_TRAIN = 0.5\n","__C.VG_IOU_TEST = 0.5\n","############################\n","\n","#VRD\n","############################\n","__C.VRD_BATCH_NUM = 30\n","__C.VRD_NUM_CLASS = 101\n","__C.VRD_NUM_RELA = 70\n","__C.VRD_LR_INIT = 0.00001\n","__C.VRD_TRAIN_ROUND = 20\n","\n","__C.VRD_BATCH_NUM_RELA = 50\n","__C.VRD_AU_PAIR = 5\n","__C.VRD_IOU_TRAIN = 0.5\n","__C.VRD_IOU_TEST = 0.5\n","###########################\n","\n","__C.IM_SIZE = 600\n","__C.IM_MAX_SIZE = 1000\n","\n","__C.TRAIN = edict()\n","\n","__C.TRAIN.WEIGHT_DECAY = 0.0005\n","\n","\n","__C.RESNET = edict()\n","\n","__C.RESNET.FIXED_BLOCKS = 1\n","\n","__C.VTR = edict()\n","\n","#the dimension of embedding space in vtranse\n","__C.VTR.VG_R = 500\n","\n","import numpy as np\n","import cv2\n","import os\n","from model.config import cfg\n","\n","\n","def generate_batch(N_total, N_each):\n","    \"\"\"\n","    This file is used to generate index of the training batch.\n","\n","    Arg:\n","        N_total:\n","        N_each:\n","    out_put:\n","        index_box: the corresponding index\n","    \"\"\"\n","    num_batch = np.int32(N_total / N_each)\n","    if N_total % N_each == 0:\n","        index_box = range(N_total)\n","    else:\n","        index_box = np.empty(shape=[N_each * (num_batch + 1)], dtype=np.int32)\n","        index_box[0:N_total] = range(N_total)\n","        N_rest = N_each * (num_batch + 1) - N_total\n","        index_box[N_total:] = np.random.randint(0, N_total, N_rest)\n","    return index_box\n","\n","\n","def generate_batch_bal(labels, N_each):\n","    N_total = len(labels)\n","    num_batch = np.int32(N_total / N_each)\n","    if N_total % N_each == 0:\n","        index_box = range(N_total)\n","    else:\n","        index_box = np.empty(shape=[N_each * (num_batch + 1)], dtype=np.int32)\n","        index_box[0:N_total] = range(N_total)\n","        N_rest = N_each * (num_batch + 1) - N_total\n","\n","        unique_labels = np.unique(labels, axis=0)\n","        N_unique = len(unique_labels)\n","        num_label = np.zeros([N_unique, ])\n","        for ii in range(N_unique):\n","            num_label[ii] = np.sum(labels == unique_labels[ii])\n","        prob_label = np.sum(num_label) / num_label\n","        prob_label = prob_label / np.sum(prob_label)\n","        index_rest = np.random.choice(N_unique, size=[N_rest, ], p=prob_label)\n","        for ii in range(N_rest):\n","            ind = index_rest[ii]\n","            ind2 = np.where(labels == unique_labels[ind])[0]\n","            a = np.random.randint(len(ind2))\n","            index_box[N_total + ii] = ind2[a]\n","    return index_box\n","\n","\n","def read_roidb(roidb_path):\n","    roidb_file = np.load(roidb_path)\n","    key = roidb_file.keys()[0]\n","    roidb_temp = roidb_file[key]\n","    roidb = roidb_temp[()]\n","    return roidb\n","\n","\n","def compute_iou(box, proposal):\n","    \"\"\"\n","    compute the IoU between box with proposal\n","    Arg:\n","        box: [x1,y1,x2,y2]\n","        proposal: N*4 matrix, each line is [p_x1,p_y1,p_x2,p_y2]\n","    output:\n","        IoU: N*1 matrix, every IoU[i] means the IoU between\n","             box with proposal[i,:]\n","    \"\"\"\n","    len_proposal = np.shape(proposal)[0]\n","    IoU = np.empty([len_proposal, 1])\n","    for i in range(len_proposal):\n","        xA = max(box[0], proposal[i, 0])\n","        yA = max(box[1], proposal[i, 1])\n","        xB = min(box[2], proposal[i, 2])\n","        yB = min(box[3], proposal[i, 3])\n","\n","        if xB < xA or yB < yA:\n","            IoU[i, 0] = 0\n","        else:\n","            area_I = (xB - xA) * (yB - yA)\n","            area1 = (box[2] - box[0]) * (box[3] - box[1])\n","            area2 = (proposal[i, 2] - proposal[i, 0]) * (proposal[i, 3] - proposal[i, 1])\n","            IoU[i, 0] = area_I / float(area1 + area2 - area_I)\n","    return IoU\n","\n","\n","def compute_iou_each(box1, box2):\n","    xA = max(box1[0], box2[0])\n","    yA = max(box1[1], box2[1])\n","    xB = min(box1[2], box2[2])\n","    yB = min(box1[3], box2[3])\n","\n","    if xB < xA or yB < yA:\n","        IoU = 0\n","    else:\n","        area_I = (xB - xA) * (yB - yA)\n","        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n","        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n","        IoU = area_I / float(area1 + area2 - area_I)\n","    return IoU\n","\n","\n","def im_preprocess(image_path):\n","    image = cv2.imread(image_path)\n","    im_orig = image.astype(np.float32, copy=True)\n","    im_orig -= np.array([[[102.9801, 115.9465, 122.7717]]])\n","\n","    im_shape = im_orig.shape\n","    im_size_min = np.min(im_shape[0:2])\n","    im_size_max = np.max(im_shape[0:2])\n","\n","    target_size = cfg.IM_SIZE\n","    max_size = cfg.IM_MAX_SIZE\n","    im_scale = float(target_size) / float(im_size_min)\n","\n","    if np.round(im_scale * im_size_max) > max_size:\n","        im_scale = float(max_size) / float(im_size_max)\n","    im = cv2.resize(im_orig, None, None, fx=im_scale, fy=im_scale,\n","                    interpolation=cv2.INTER_LINEAR)\n","    im_shape_new = np.shape(im)\n","    im_use = np.zeros([1, im_shape_new[0], im_shape_new[1], im_shape_new[2]])\n","    im_use[0, :, :, :] = im\n","    return im_use, im_scale\n","\n","\n","def get_blob_pred(roidb_use, im_scale, index_sp, N_each_batch, batch_id):\n","    blob = {}\n","    sub_box = roidb_use['sub_box_gt'] * im_scale\n","    obj_box = roidb_use['obj_box_gt'] * im_scale\n","    rela = np.int32(roidb_use['rela_gt'])\n","    index = roidb_use['index_pred']\n","\n","    index_use = index[batch_id * N_each_batch: (batch_id + 1) * N_each_batch]\n","    sub_box_use = sub_box[index_use, :]\n","    obj_box_use = obj_box[index_use, :]\n","    rela_use = rela[index_use]\n","\n","    blob['sub_box'] = sub_box_use\n","    blob['obj_box'] = obj_box_use\n","    blob['rela'] = rela_use\n","    return blob\n","\n","\n","def get_blob_rela(roidb_use, im_scale, index_sp, N_each_batch, batch_id):\n","    blob = {}\n","    sub_box = roidb_use['sub_box_dete'] * im_scale\n","    obj_box = roidb_use['obj_box_dete'] * im_scale\n","    rela = np.int32(roidb_use['rela_dete'])\n","    index = roidb_use['index_rela']\n","\n","    index_use = index[batch_id * N_each_batch: (batch_id + 1) * N_each_batch]\n","    sub_box_use = sub_box[index_use, :]\n","    obj_box_use = obj_box[index_use, :]\n","    rela_use = rela[index_use]\n","\n","    blob['sub_box'] = sub_box_use\n","    blob['obj_box'] = obj_box_use\n","    blob['rela'] = rela_use\n","    return blob\n","\n","\n","def pred_recall(test_roidb, pred_roidb, N_recall):\n","    N_right = 0.0\n","    N_total = 0.0\n","    N_data = len(test_roidb)\n","    for i in range(N_data):\n","        gt_rela = test_roidb[i]['rela_gt']\n","        if len(gt_rela) == 0:\n","            continue\n","        pred_rela = pred_roidb[i]['pred_rela']\n","        pred_rela_score = pred_roidb[i]['pred_rela_score']\n","        N_rela = len(gt_rela)\n","        N_total = N_total + N_rela\n","        if N_rela <= N_recall:\n","            N_right = N_right + np.sum(np.float32(gt_rela == pred_rela))\n","        else:\n","            sort_score = np.sort(pred_rela_score)[::-1]\n","            thresh = sort_score[N_recall]\n","            for j in range(N_rela):\n","                if pred_rela_score[j] >= thresh:\n","                    N_right = N_right + np.float32(gt_rela[j] == pred_rela[j])\n","\n","    acc = N_right / N_total\n","    return acc\n","\n","\n","def rela_recall(test_roidb, pred_roidb, N_recall):\n","    N_right = 0.0\n","    N_total = 0.0\n","    N_data = len(test_roidb)\n","    num_right = np.zeros([N_data, ])\n","    for i in range(N_data):\n","        rela_gt = test_roidb[i]['rela_gt']\n","        if len(rela_gt) == 0:\n","            continue\n","        sub_gt = test_roidb[i]['sub_gt']\n","        obj_gt = test_roidb[i]['obj_gt']\n","        sub_box_gt = test_roidb[i]['sub_box_gt']\n","        obj_box_gt = test_roidb[i]['obj_box_gt']\n","\n","        pred_rela = pred_roidb[i]['pred_rela']\n","        pred_rela_score = pred_roidb[i]['pred_rela_score']\n","        sub_dete = pred_roidb[i]['sub_dete']\n","        obj_dete = pred_roidb[i]['obj_dete']\n","        sub_box_dete = pred_roidb[i]['sub_box_dete']\n","        obj_box_dete = pred_roidb[i]['obj_box_dete']\n","\n","        N_rela = len(rela_gt)\n","        N_total = N_total + N_rela\n","\n","        N_pred = len(pred_rela)\n","\n","        sort_score = np.sort(pred_rela_score)[::-1]\n","        if N_recall >= N_pred:\n","            thresh = -1\n","        else:\n","            thresh = sort_score[N_recall]\n","\n","        detected_gt = np.zeros([N_rela, ])\n","        for j in range(N_pred):\n","            if pred_rela_score[j] <= thresh:\n","                continue\n","\n","            for k in range(N_rela):\n","                if detected_gt[k] == 1:\n","                    continue\n","                if (sub_gt[k] == sub_dete[j]) and (obj_gt[k] == obj_dete[j]) and (rela_gt[k] == pred_rela[j]):\n","                    s_iou = compute_iou_each(sub_box_dete[j], sub_box_gt[k])\n","                    o_iou = compute_iou_each(obj_box_dete[j], obj_box_gt[k])\n","                    if (s_iou >= 0.5) and (o_iou >= 0.5):\n","                        detected_gt[k] = 1\n","                        N_right = N_right + 1\n","                        num_right[i] = num_right[i] + 1\n","\n","    acc = N_right / N_total\n","    print(N_right)\n","    print(N_total)\n","    return acc, num_right\n","\n","\n","def phrase_recall(test_roidb, pred_roidb, N_recall):\n","    N_right = 0.0\n","    N_total = 0.0\n","    N_data = len(test_roidb)\n","    num_right = np.zeros([N_data, ])\n","    for i in range(N_data):\n","        rela_gt = test_roidb[i]['rela_gt']\n","        if len(rela_gt) == 0:\n","            continue\n","\n","        N_rela = len(rela_gt)\n","        sub_gt = test_roidb[i]['sub_gt']\n","        obj_gt = test_roidb[i]['obj_gt']\n","        sub_box_gt = test_roidb[i]['sub_box_gt']\n","        obj_box_gt = test_roidb[i]['obj_box_gt']\n","        phrase_gt = generate_phrase_box(sub_box_gt, obj_box_gt)\n","\n","        pred_rela = pred_roidb[i]['pred_rela']\n","        pred_rela_score = pred_roidb[i]['pred_rela_score']\n","        sub_dete = pred_roidb[i]['sub_dete']\n","        obj_dete = pred_roidb[i]['obj_dete']\n","        sub_box_dete = pred_roidb[i]['sub_box_dete']\n","        obj_box_dete = pred_roidb[i]['obj_box_dete']\n","        phrase_dete = generate_phrase_box(sub_box_dete, obj_box_dete)\n","        N_pred = len(pred_rela)\n","\n","        N_total = N_total + N_rela\n","\n","        sort_score = np.sort(pred_rela_score)[::-1]\n","        if N_recall >= N_pred:\n","            thresh = -1\n","        else:\n","            thresh = sort_score[N_recall]\n","\n","        detected_gt = np.zeros([N_rela, ])\n","        for j in range(N_pred):\n","            if pred_rela_score[j] <= thresh:\n","                continue\n","\n","            for k in range(N_rela):\n","                if detected_gt[k] == 1:\n","                    continue\n","                if (sub_gt[k] == sub_dete[j]) and (obj_gt[k] == obj_dete[j]) and (rela_gt[k] == pred_rela[j]):\n","                    iou = compute_iou_each(phrase_dete[j], phrase_gt[k])\n","                    if iou >= 0.5:\n","                        detected_gt[k] = 1\n","                        N_right = N_right + 1\n","                        num_right[i] = num_right[i] + 1\n","\n","    acc = N_right / N_total\n","    print(N_right)\n","    print(N_total)\n","    return acc, num_right\n","\n","\n","def print_pred_res(test_roidb, pred_roidb, res_name, N_rela):\n","    N_pred_rela = np.zeros([N_rela, ])\n","    N_right_rela = np.zeros([N_rela, ])\n","    N_gt_rela = np.zeros([N_rela, ])\n","    N_acc = np.zeros([N_rela, ])\n","    N_pred_other = np.zeros([N_rela, N_rela])\n","\n","    N_pred = len(pred_roidb)\n","    for i in range(N_pred):\n","        pred_rela = np.int32(pred_roidb[i]['pred_rela'])\n","        gt_rela = np.int32(test_roidb[i]['rela_gt'])\n","        for k in range(len(gt_rela)):\n","            N_pred_rela[pred_rela[k]] += 1\n","            N_gt_rela[gt_rela[k]] += 1\n","            N_pred_other[gt_rela[k]][pred_rela[k]] += 1\n","            if pred_rela[k] == gt_rela[k]:\n","                N_right_rela[gt_rela[k]] += 1\n","\n","    for k in range(N_rela):\n","        if N_gt_rela[k] == 0:\n","            N_acc[k] = -1\n","            continue\n","        N_acc[k] = (N_right_rela[k] + 0.0) / N_gt_rela[k]\n","\n","    text_file = open(res_name, \"aw\")\n","    for k in range(N_rela):\n","        text_file.write('k: {0}, acc: {1}\\n'.format(k, N_acc[k]))\n","    for k in range(N_rela):\n","        text_file.write('k: {0}, num of pred: {1}\\n'.format(k, N_pred_rela[k]))\n","    for k in range(N_rela):\n","        text_file.write('k: {0}, others: {1}\\n'.format(k, np.where(N_pred_other[k] > 0)[0]))\n","    text_file.close()\n","\n","\n","def generate_phrase_box(sbox, obox):\n","    N_box = len(sbox)\n","    phrase = np.zeros([N_box, 4])\n","    for i in range(N_box):\n","        phrase[i, 0] = min(sbox[i, 0], obox[i, 0])\n","        phrase[i, 1] = min(sbox[i, 1], obox[i, 1])\n","        phrase[i, 2] = max(sbox[i, 2], obox[i, 2])\n","        phrase[i, 3] = max(sbox[i, 2], obox[i, 3])\n","    return phrase\n","\n","\n","def extract_detected_box(dete_box):\n","    N_cls = len(dete_box['pred_boxes'])\n","    pred_box = dete_box['pred_boxes']\n","    detected_cls = np.zeros([1000, ])\n","    detected_box = np.zeros([1000, 4])\n","    detected_score = np.zeros([1000, ])\n","    t = 0\n","    for i in range(N_cls):\n","        l = len(pred_box[i])\n","        if l == 0:\n","            continue\n","        box_temp = pred_box[i]\n","        detected_box[t:t + l] = box_temp[:, 0:4]\n","        detected_cls[t:t + l] = i\n","        detected_score[t:t + l] = box_temp[:, 4]\n","        t = t + l\n","    detected_box = detected_box[0:t]\n","    detected_cls = detected_cls[0:t]\n","    detected_score = detected_score[0:t]\n","    return detected_box, detected_cls, detected_score\n","\n","\n","def extract_roidb_box(roidb):\n","    sbox = roidb['sub_box_gt']\n","    obox = roidb['obj_box_gt']\n","    roidb_box = np.concatenate((roidb['sub_box_gt'], roidb['obj_box_gt']), axis=0)\n","    roidb_cls = np.concatenate((roidb['sub_gt'], roidb['obj_gt']), axis=0)\n","    roidb_rela = roidb['rela_gt']\n","    N_rela = len(roidb_rela)\n","    unique_boxes, unique_inds = np.unique(roidb_box, axis=0, return_index=True)\n","    unique_cls = roidb_cls[unique_inds]\n","    rela_box_index = np.zeros([N_rela, 2])\n","    for i in range(N_rela):\n","        rela_box_index[i, 0] = np.where(unique_boxes == sbox[i])[0][0]\n","        rela_box_index[i, 1] = np.where(unique_boxes == obox[i])[0][0]\n","    return unique_cls, unique_boxes, roidb_rela, rela_box_index\n","\n","\n","def generate_au_box(unique_boxes, detected_box, iou_l):\n","    N_unique = len(unique_boxes)\n","    au_box = []\n","    for i in range(N_unique):\n","        box_temp = unique_boxes[i]\n","        iou = compute_iou(box_temp, detected_box)\n","        index_temp = np.where(iou > iou_l)[0]\n","        box_use = detected_box[index_temp]\n","        box_use = np.vstack((box_use, box_temp))\n","        au_box.append(box_use)\n","    return au_box\n","\n","\n","def generate_rela_info(au_box, index, N_each_pair):\n","    s_id = np.int32(index[0])\n","    o_id = np.int32(index[1])\n","    sbox = au_box[s_id]\n","    obox = au_box[o_id]\n","    N_s = len(sbox)\n","    N_o = len(obox)\n","    sa = np.random.randint(0, N_s, [N_each_pair, ])\n","    oa = np.random.randint(0, N_o, [N_each_pair, ])\n","    sbox_use = sbox[sa]\n","    obox_use = obox[oa]\n","    return sbox_use, obox_use\n","\n","\n","def generate_train_rela_roidb(roidb, dete_box, iou_l, N_each_batch, N_each_pair):\n","    unique_cls, unique_boxes, roidb_rela, rela_box_index = extract_roidb_box(roidb)\n","    detected_box, detected_cls, detected_score = extract_detected_box(dete_box)\n","    au_box = generate_au_box(unique_boxes, detected_box, iou_l)\n","\n","    N_rela = len(roidb_rela)\n","    for i in range(N_rela):\n","        sbox, obox = generate_rela_info(au_box, rela_box_index[i], N_each_pair)\n","        s_id = np.int32(rela_box_index[i, 0])\n","        o_id = np.int32(rela_box_index[i, 1])\n","        sb = np.zeros([N_each_pair, ]) + unique_cls[s_id]\n","        ob = np.zeros([N_each_pair, ]) + unique_cls[o_id]\n","        rela = np.zeros([N_each_pair, ]) + roidb_rela[i]\n","        if i == 0:\n","            sub_box_dete = sbox\n","            obj_box_dete = obox\n","            sub_dete = sb\n","            obj_dete = ob\n","            rela_dete = rela\n","        else:\n","            sub_box_dete = np.vstack((sub_box_dete, sbox))\n","            obj_box_dete = np.vstack((obj_box_dete, obox))\n","            sub_dete = np.concatenate((sub_dete, sb), axis=0)\n","            obj_dete = np.concatenate((obj_dete, ob), axis=0)\n","            rela_dete = np.concatenate((rela_dete, rela), axis=0)\n","\n","    index_rela = generate_batch(len(rela_dete), N_each_batch)\n","\n","    roidb_temp = {'image': roidb['image'], 'au_box': au_box, 'rela_box_index': rela_box_index,\n","                  'unique_cls': unique_cls, 'unique_box': unique_boxes, 'rela_gt': roidb_rela,\n","                  'sub_box_dete': sub_box_dete, 'obj_box_dete': obj_box_dete, 'sub_dete': sub_dete,\n","                  'obj_dete': obj_dete, 'rela_dete': rela_dete, 'index_rela': index_rela}\n","    return roidb_temp\n","\n","\n","def generate_test_rela_roidb(roidb, dete_box, N_each_batch):\n","    detected_box, detected_cls, detected_score = extract_detected_box(dete_box)\n","    N_dete = len(detected_box)\n","    sub_box_dete = np.zeros([N_dete * (N_dete - 1), 4])\n","    obj_box_dete = np.zeros([N_dete * (N_dete - 1), 4])\n","    sub_dete = np.zeros([N_dete * (N_dete - 1), ])\n","    obj_dete = np.zeros([N_dete * (N_dete - 1), ])\n","    sub_score = np.zeros([N_dete * (N_dete - 1), ])\n","    obj_score = np.zeros([N_dete * (N_dete - 1), ])\n","\n","    t = 0\n","    for i in range(N_dete):\n","        for j in range(N_dete):\n","            if j == i:\n","                continue\n","            sub_box_dete[t] = detected_box[i]\n","            obj_box_dete[t] = detected_box[j]\n","            sub_dete[t] = detected_cls[i]\n","            obj_dete[t] = detected_cls[j]\n","            sub_score[t] = detected_score[i]\n","            obj_score[t] = detected_score[j]\n","            t = t + 1\n","    sub_box_dete = sub_box_dete[0:t]\n","    obj_box_dete = obj_box_dete[0:t]\n","    sub_dete = sub_dete[0:t]\n","    obj_dete = obj_dete[0:t]\n","    sub_score = sub_score[0:t]\n","    obj_score = obj_score[0:t]\n","    index_rela = generate_batch(len(sub_box_dete), N_each_batch)\n","    rela_dete = np.zeros([len(sub_box_dete), ])\n","\n","    roidb_temp = {'image': roidb['image'], 'rela_gt': roidb['rela_gt'], 'sub_gt': roidb['sub_gt'],\n","                  'obj_gt': roidb['obj_gt'],\n","                  'sub_box_dete': sub_box_dete, 'obj_box_dete': obj_box_dete, 'sub_dete': sub_dete,\n","                  'obj_dete': obj_dete,\n","                  'detected_box': detected_box, 'detected_cls': detected_cls, 'sub_box_gt': roidb['sub_box_gt'],\n","                  'obj_box_gt': roidb['obj_box_gt'], 'sub_score': sub_score, 'obj_score': obj_score,\n","                  'index_rela': index_rela,\n","                  'rela_dete': rela_dete}\n","\n","    return roidb_temp\n","\n","\n","class VTranse(object):\n","\tdef __init__(self):\n","\t\tself.predictions = {}\n","\t\tself.losses = {}\n","\t\tself.layers = {}\n","\t\tself.feat_stride = [16, ]\n","\t\tself.scope = 'vgg_16'\n","\n","\tdef create_graph(self, N_each_batch, index_sp, index_cls, num_classes, num_predicates):\n","\t\tself.image = tf.placeholder(tf.float32, shape=[1, None, None, 3])\n","\t\tself.sbox = tf.placeholder(tf.float32, shape=[N_each_batch, 4])\n","\t\tself.obox = tf.placeholder(tf.float32, shape=[N_each_batch, 4])\n","\t\tself.sub_sp_info = tf.placeholder(tf.float32, shape=[N_each_batch, 4])\n","\t\tself.ob_sp_info = tf.placeholder(tf.float32, shape=[N_each_batch, 4])\n","\t\tself.rela_label = tf.placeholder(tf.int32, shape=[N_each_batch,])\n","\t\tself.keep_prob = tf.placeholder(tf.float32)\n","\t\tself.index_sp = index_sp\n","\t\tself.index_cls = index_cls\n","\t\tself.num_classes = num_classes\n","\t\tself.num_predicates = num_predicates\n","\t\tself.N_each_batch = N_each_batch\n","\n","\t\tself.build_dete_network()\n","\t\tself.build_rd_network()\n","\t\tself.add_rd_loss()\n","\n","\n","\tdef build_dete_network(self, is_training=True):\n","\t\tnet_conv = self.image_to_head(is_training)\n","\t\tsub_pool5 = self.crop_pool_layer(net_conv, self.sbox, \"sub_pool5\")\n","\t\tob_pool5 = self.crop_pool_layer(net_conv, self.obox, \"ob_pool5\")\n","\t\tsub_fc7 = self.head_to_tail(sub_pool5, is_training, reuse = False)\n","\t\tob_fc7 = self.head_to_tail(ob_pool5, is_training, reuse = True)\n","\n","\t\twith tf.variable_scope(self.scope, self.scope):\n","\t\t\t# region classification\n","\t\t\tsub_cls_prob, sub_cls_pred = self.region_classification(sub_fc7, is_training, reuse = False)\n","\t\twith tf.variable_scope(self.scope, self.scope):\n","\t\t\t# region classification\n","\t\t\tob_cls_prob, ob_cls_pred = self.region_classification(ob_fc7, is_training, reuse = True)\n","\n","\t\tself.predictions['sub_cls_prob'] = sub_cls_prob\n","\t\tself.predictions['sub_cls_pred'] = sub_cls_pred\n","\t\tself.predictions['ob_cls_prob'] = ob_cls_prob\n","\t\tself.predictions['ob_cls_pred'] = ob_cls_pred\n","\t\tself.layers['sub_pool5'] = sub_pool5\n","\t\tself.layers['ob_pool5'] = ob_pool5\n","\t\tself.layers['sub_fc7'] = sub_fc7\n","\t\tself.layers['ob_fc7'] = ob_fc7\n","\n","\tdef image_to_head(self, is_training, reuse=False):\n","\t\twith tf.variable_scope(self.scope, self.scope, reuse=reuse):\n","\t\t\tnet = slim.repeat(self.image, 2, slim.conv2d, 64, [3, 3],\n","\t\t\t\ttrainable=is_training, scope='conv1')\n","\t\t\tnet = slim.max_pool2d(net, [2, 2], padding='SAME', scope='pool1')\n","\t\t\tnet = slim.repeat(net, 2, slim.conv2d, 128, [3, 3],\n","\t\t\t\ttrainable=is_training, scope='conv2')\n","\t\t\tnet = slim.max_pool2d(net, [2, 2], padding='SAME', scope='pool2')\n","\t\t\tnet = slim.repeat(net, 3, slim.conv2d, 256, [3, 3],\n","\t\t\t\ttrainable=is_training, scope='conv3')\n","\t\t\tnet = slim.max_pool2d(net, [2, 2], padding='SAME', scope='pool3')\n","\t\t\tnet = slim.repeat(net, 3, slim.conv2d, 512, [3, 3],\n","\t\t\t\ttrainable=is_training, scope='conv4')\n","\t\t\tnet = slim.max_pool2d(net, [2, 2], padding='SAME', scope='pool4')\n","\t\t\tnet_conv = slim.repeat(net, 3, slim.conv2d, 512, [3, 3],\n","\t\t\t\ttrainable=is_training, scope='conv5')\n","\n","\t\t\tself.layers['head'] = net_conv\n","\t\t\treturn net_conv\n","\n","\tdef head_to_tail(self, pool5, is_training, reuse=False):\n","\t\twith tf.variable_scope(self.scope, self.scope, reuse=reuse):\n","\t\t\tpool5_flat = slim.flatten(pool5, scope='flatten')\n","\t\t\tfc6 = slim.fully_connected(pool5_flat, 4096, scope='fc6')\n","\t\t\tfc6 = slim.dropout(fc6, keep_prob=self.keep_prob, is_training=True,\n","\t\t\t\t\tscope='dropout6')\n","\t\t\tfc7 = slim.fully_connected(fc6, 4096, scope='fc7')\n","\t\t\tfc7 = slim.dropout(fc7, keep_prob=self.keep_prob, is_training=True,\n","\t\t\t\t\tscope='dropout7')\n","\n","\t\t\treturn fc7\n","\n","\tdef crop_pool_layer(self, bottom, rois, name):\n","\t\t\"\"\"\n","\t\tNotice that the input rois is a N*4 matrix, and the coordinates of x,y should be original x,y times im_scale.\n","\t\t\"\"\"\n","\t\twith tf.variable_scope(name) as scope:\n","\t\t\tn=tf.to_int32(rois.shape[0])\n","\t\t\tbatch_ids = tf.zeros([n,],dtype=tf.int32)\n","\t\t\t# Get the normalized coordinates of bboxes\n","\t\t\tbottom_shape = tf.shape(bottom)\n","\t\t\theight = (tf.to_float(bottom_shape[1]) - 1.) * np.float32(self.feat_stride[0])\n","\t\t\twidth = (tf.to_float(bottom_shape[2]) - 1.) * np.float32(self.feat_stride[0])\n","\t\t\tx1 = tf.slice(rois, [0, 0], [-1, 1], name=\"x1\") / width\n","\t\t\ty1 = tf.slice(rois, [0, 1], [-1, 1], name=\"y1\") / height\n","\t\t\tx2 = tf.slice(rois, [0, 2], [-1, 1], name=\"x2\") / width\n","\t\t\ty2 = tf.slice(rois, [0, 3], [-1, 1], name=\"y2\") / height\n","\t\t\t# Won't be back-propagated to rois anyway, but to save time\n","\t\t\tbboxes = tf.stop_gradient(tf.concat([y1, x1, y2, x2], 1))\n","\t\t\tcrops = tf.image.crop_and_resize(bottom, bboxes, tf.to_int32(batch_ids), [cfg.POOLING_SIZE*2, cfg.POOLING_SIZE*2], method='bilinear',\n","\t\t\t\t\t\t\t\t\t\t\t name=\"crops\")\n","\t\t\tpooling = max_pool(crops, 2, 2, 2, 2, name=\"max_pooling\")\n","\t\treturn pooling\n","\n","\n","\tdef region_classification(self, fc7, is_training, reuse = False):\n","\t\tcls_score = slim.fully_connected(fc7, self.num_classes,\n","\t\t\t\t\t\t\t\t\t\t activation_fn=None, scope='cls_score', reuse=reuse)\n","\t\tprint(\"cls_score's shape: {0}\".format(cls_score.get_shape()))\n","\t\tcls_prob = tf.nn.softmax(cls_score, name=\"cls_prob\")\n","\t\tcls_pred = tf.argmax(cls_score, axis=1, name=\"cls_pred\")\n","\n","\t\treturn cls_prob, cls_pred\n","\n","\tdef build_rd_network(self):\n","\t\tsub_sp_info = self.sub_sp_info\n","\t\tob_sp_info = self.ob_sp_info\n","\t\tsub_cls_prob = self.predictions['sub_cls_prob']\n","\t\tob_cls_prob = self.predictions['ob_cls_prob']\n","\t\tsub_fc = self.layers['sub_fc7']\n","\t\tob_fc = self.layers['ob_fc7']\n","\n","\t\tif self.index_sp:\n","\t\t\tsub_fc = tf.concat([sub_fc, sub_sp_info], axis = 1)\n","\t\t\tob_fc = tf.concat([ob_fc, ob_sp_info], axis = 1)\n","\t\tif self.index_cls:\n","\t\t\tsub_fc = tf.concat([sub_fc, sub_cls_prob], axis = 1)\n","\t\t\tob_fc = tf.concat([ob_fc, ob_cls_prob], axis = 1)\n","\n","\t\tsub_fc1 = slim.fully_connected(sub_fc, cfg.VTR.VG_R,\n","\t\t\t\t\t\t\t\t\t\t activation_fn=tf.nn.relu, scope='RD_sub_fc1')\n","\t\tob_fc1 = slim.fully_connected(ob_fc, cfg.VTR.VG_R,\n","\t\t\t\t\t\t\t\t\t\t activation_fn=tf.nn.relu, scope='RD_ob_fc1')\n","\t\tdif_fc1 = ob_fc1 - sub_fc1\n","\t\trela_score = slim.fully_connected(dif_fc1, self.num_predicates,\n","\t\t\t\t\t\t\t\t\t\t activation_fn=None, scope='RD_fc2')\n","\t\trela_prob = tf.nn.softmax(rela_score)\n","\t\tself.layers['rela_score'] = rela_score\n","\t\tself.layers['rela_prob'] = rela_prob\n","\n","\tdef add_rd_loss(self):\n","\t\trela_score = self.layers['rela_score']\n","\t\trela_prob = self.layers['rela_prob']\n","\t\trela_label = self.rela_label\n","\t\trd_loss = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(\n","\t\t\t\t\t\t\t\t\tlabels = rela_label, logits = rela_score) )\n","\t\tself.losses['rd_loss'] = rd_loss\n","\n","\t\tacc_each = tf.nn.in_top_k(rela_score, rela_label, 1)\n","\t\tself.losses['acc_each'] = acc_each\n","\t\tself.losses['acc'] = tf.reduce_mean( tf.cast(acc_each, tf.float32) )\n","\n","\t\trela_pred = tf.argmax(rela_score, 1)\n","\t\tself.predictions['rela_pred'] = rela_pred\n","\n","\t\trela_max_prob = tf.reduce_max(rela_prob, 1)\n","\t\tself.predictions['rela_max_prob'] = rela_max_prob\n","\n","\tdef train_predicate(self, sess, roidb_use, RD_train):\n","\t\tim, im_scale = im_preprocess(roidb_use['image'])\n","\t\tbatch_num = len(roidb_use['index_pred'])/self.N_each_batch\n","\t\tRD_loss = 0.0\n","\t\tacc = 0.0\n","\t\tfor batch_id in range(np.int32(batch_num)):\n","\t\t\tblob = get_blob_pred(roidb_use, im_scale, self.index_sp, self.N_each_batch, batch_id)\n","\t\t\tfeed_dict = {self.image: im, self.sbox: blob['sub_box'], self.obox: blob['obj_box'], self.rela_label: blob['rela'],\n","\t\t\t\t\t\t self.keep_prob: 0.5}\n","\t\t\t_, losses = sess.run([RD_train, self.losses], feed_dict = feed_dict)\n","\t\t\tRD_loss = RD_loss + losses['rd_loss']\n","\t\t\tacc = acc + losses['acc']\n","\n","\t\tRD_loss = RD_loss/batch_num\n","\t\tacc = acc/batch_num\n","\t\treturn RD_loss, acc\n","\n","\tdef train_rela(self, sess, roidb_use, RD_train):\n","\t\tim, im_scale = im_preprocess(roidb_use['image'])\n","\t\tbatch_num = len(roidb_use['index_rela'])/self.N_each_batch\n","\t\tRD_loss = 0.0\n","\t\tacc = 0.0\n","\t\tfor batch_id in range(np.int32(batch_num)):\n","\t\t\tblob = get_blob_rela(roidb_use, im_scale, self.index_sp, self.N_each_batch, batch_id)\n","\t\t\tfeed_dict = {self.image: im, self.sbox: blob['sub_box'], self.obox: blob['obj_box'], self.rela_label: blob['rela'],\n","\t\t\t\t\t\t self.keep_prob: 0.5}\n","\t\t\t_, losses = sess.run([RD_train, self.losses], feed_dict = feed_dict)\n","\t\t\tRD_loss = RD_loss + losses['rd_loss']\n","\t\t\tacc = acc + losses['acc']\n","\n","\t\tRD_loss = RD_loss/batch_num\n","\t\tacc = acc/batch_num\n","\t\treturn RD_loss, acc\n","\n","\tdef val_predicate(self, sess, roidb_use):\n","\t\tim, im_scale = im_preprocess(roidb_use['image'])\n","\t\tbatch_num = len(roidb_use['index_pred'])/self.N_each_batch\n","\t\tRD_loss = 0.0\n","\t\tacc = 0.0\n","\t\tfor batch_id in range(np.int32(batch_num)):\n","\t\t\tblob = get_blob_pred(roidb_use, im_scale, self.index_sp, self.N_each_batch, batch_id)\n","\t\t\tfeed_dict = {self.image: im, self.sbox: blob['sub_box'], self.obox: blob['obj_box'], self.rela_label: blob['rela'],\n","\t\t\t\t\t\t self.keep_prob: 1}\n","\t\t\tlosses = sess.run(self.losses, feed_dict = feed_dict)\n","\t\t\tRD_loss = RD_loss + losses['rd_loss']\n","\t\t\tacc = acc + losses['acc']\n","\n","\t\tRD_loss = RD_loss/batch_num\n","\t\tacc = acc/batch_num\n","\t\treturn RD_loss, acc\n","\n","\tdef val_rela(self, sess, roidb_use):\n","\t\tim, im_scale = im_preprocess(roidb_use['image'])\n","\t\tbatch_num = len(roidb_use['index_rela'])/self.N_each_batch\n","\t\tRD_loss = 0.0\n","\t\tacc = 0.0\n","\t\tfor batch_id in range(np.int32(batch_num)):\n","\t\t\tblob = get_blob_rela(roidb_use, im_scale, self.index_sp, self.N_each_batch, batch_id)\n","\t\t\tfeed_dict = {self.image: im, self.sbox: blob['sub_box'], self.obox: blob['obj_box'], self.rela_label: blob['rela'],\n","\t\t\t\t\t\t self.keep_prob: 1}\n","\t\t\tlosses = sess.run(self.losses, feed_dict = feed_dict)\n","\t\t\tRD_loss = RD_loss + losses['rd_loss']\n","\t\t\tacc = acc + losses['acc']\n","\n","\t\tRD_loss = RD_loss/batch_num\n","\t\tacc = acc/batch_num\n","\t\treturn RD_loss, acc\n","\n","\tdef test_predicate(self, sess, roidb_use):\n","\t\tim, im_scale = im_preprocess(roidb_use['image'])\n","\t\tbatch_num = len(roidb_use['index_pred'])/self.N_each_batch\n","\t\tpred_rela = np.zeros([len(roidb_use['index_pred']),])\n","\t\tpred_rela_score = np.zeros([len(roidb_use['index_pred']),])\n","\n","\t\tfor batch_id in range(np.int32(batch_num)):\n","\t\t\tblob = get_blob_pred(roidb_use, im_scale, self.index_sp, self.N_each_batch, batch_id)\n","\t\t\tfeed_dict = {self.image: im, self.sbox: blob['sub_box'], self.obox: blob['obj_box'], self.rela_label: blob['rela'],\n","\t\t\t\t\t\t self.keep_prob: 1}\n","\t\t\tpredictions = sess.run(self.predictions, feed_dict = feed_dict)\n","\t\t\tpred_rela[batch_id*self.N_each_batch:(batch_id+1)*self.N_each_batch] = predictions['rela_pred'][:]\n","\t\t\tpred_rela_score[batch_id*self.N_each_batch:(batch_id+1)*self.N_each_batch] = predictions['rela_max_prob'][:]\n","\t\tN_rela = len(roidb_use['rela_gt'])\n","\t\tpred_rela = pred_rela[0:N_rela]\n","\t\tpred_rela_score = pred_rela_score[0:N_rela]\n","\t\treturn pred_rela, pred_rela_score\n","\n","\tdef test_rela(self, sess, roidb_use):\n","\t\tim, im_scale = im_preprocess(roidb_use['image'])\n","\t\tbatch_num = len(roidb_use['index_rela'])/self.N_each_batch\n","\t\tpred_rela = np.zeros([len(roidb_use['index_rela']),])\n","\t\tpred_rela_score = np.zeros([len(roidb_use['index_rela']),])\n","\n","\t\tfor batch_id in range(np.int32(batch_num)):\n","\t\t\tblob = get_blob_rela(roidb_use, im_scale, self.index_sp, self.N_each_batch, batch_id)\n","\t\t\tfeed_dict = {self.image: im, self.sbox: blob['sub_box'], self.obox: blob['obj_box'], self.rela_label: blob['rela'],\n","\t\t\t\t\t\t self.keep_prob: 1}\n","\t\t\tpredictions = sess.run(self.predictions, feed_dict = feed_dict)\n","\t\t\tpred_rela[batch_id*self.N_each_batch:(batch_id+1)*self.N_each_batch] = predictions['rela_pred'][:]\n","\t\t\tpred_rela_score[batch_id*self.N_each_batch:(batch_id+1)*self.N_each_batch] = predictions['rela_max_prob'][:]\n","\t\tN_rela = len(roidb_use['rela_dete'])\n","\t\tpred_rela = pred_rela[0:N_rela]\n","\t\tpred_rela_score = pred_rela_score[0:N_rela]\n","\t\treturn pred_rela, pred_rela_score\n","\n","def conv(x, h, w, K, s_y, s_x, name, relu = True, reuse=False, padding='SAME'):\n","\t\"\"\"\n","\tArgs:\n","\t\tx: input\n","\t\th: height of filter\n","\t\tw: width of filter\n","\t\tK: number of filters\n","\t\ts_y: stride of height of filter\n","\t\ts_x: stride of width of filter\n","\t\"\"\"\n","\t#c means the number of input channels\n","\tc = int(x.get_shape()[-1])\n","\n","\twith tf.variable_scope(name, reuse=reuse) as scope:\n","\t\tweights = tf.get_variable('weights', shape=[h,w,c,K])\n","\t\tbiases = tf.get_variable('biases', shape=[K])\n","\n","\t\tconv_value = tf.nn.conv2d(x, weights, strides = [1,s_y,s_x,1], padding = padding)\n","\t\tadd_baises_value = tf.reshape(tf.nn.bias_add(conv_value, biases), tf.shape(conv_value))\n","\t\tif relu==True:\n","\t\t\trelu_value = tf.nn.relu(add_baises_value, name=scope.name)\n","\t\telse:\n","\t\t\trelu_value = add_baises_value\n","\n","\t\treturn relu_value\n","\n","def fc(x,K,name,relu=True,reuse=False):\n","\t\"\"\"\n","\tArgs:\n","\t\tx: input\n","\t\tK: the dimension of the output\n","\t\"\"\"\n","\t#c means the number of input channels\n","\n","\tc = int(x.get_shape()[1])\n","\twith tf.variable_scope(name, reuse=reuse) as scope:\n","\t\tweights = tf.get_variable('weights', shape=[c,K])\n","\t\tbiases = tf.get_variable('biases',shape=[K])\n","\t\trelu_value = tf.nn.xw_plus_b(x,weights,biases,name = scope.name)\n","\t\tif relu:\n","\t\t\tresult_value = tf.nn.relu(relu_value)\n","\t\telse:\n","\t\t\tresult_value = relu_value\n","\t\treturn result_value\n","\n","def max_pool(x, h, w, s_y, s_x, name, padding='SAME'):\n","\treturn tf.nn.max_pool(x, ksize=[1,h,w,1], strides=[1, s_x, s_y, 1], padding=padding, name=name)\n","\n","def avg_pool(x, h, w, s_y, s_x, name, padding='SAME'):\n","\treturn tf.nn.avg_pool(x, ksize=[1,h,w,1], strides=[1, s_x, s_y, 1], padding=padding, name=name)\n","\n","def dropout(x, keep_prob):\n","\treturn tf.nn.dropout(x, keep_prob)\n","\n","def leaky_relu(x, alpha):\n","\treturn tf.maximum(x, alpha * x)\n","\n","#_________________________________________\n","N_cls = cfg.VRD_NUM_CLASS\n","N_rela = cfg.VRD_NUM_RELA\n","N_each_batch = cfg.VRD_BATCH_NUM\n","lr_init = cfg.VRD_LR_INIT\n","\n","\n","index_sp = False\n","index_cls = False\n","\n","vnet = VTranse()\n","vnet.create_graph(N_each_batch, index_sp, index_cls, N_cls, N_rela)\n","\n","roidb_path = cfg.DIR + 'input/vrd_roidb.npz'\n","res_path = cfg.DIR + 'pretrained_para/vrd_vgg_pretrained.ckpt'\n","\n","roidb_read = read_roidb(roidb_path)\n","train_roidb = roidb_read['train_roidb']\n","test_roidb = roidb_read['test_roidb']\n","N_train = len(train_roidb)\n","N_test = len(test_roidb)\n","N_round = 10\n","N_show = 100\n","N_save = N_train\n","N_val = N_test\n","\n","total_var = tf.trainable_variables()\n","restore_var = [var for var in total_var if 'vgg_16' in var.name]\n","cls_score_var = [var for var in total_var if 'cls_score' in var.name]\n","res_var = [item for item in restore_var if item not in cls_score_var]\n","\n","saver_res = tf.train.Saver(var_list = restore_var)\n","\n","RD_var = [var for var in total_var if 'RD' in var.name]\n","\n","saver = tf.train.Saver(max_to_keep = 200)\n","for var in RD_var:\n","\tprint(var)\n","\n","optimizer = tf.train.AdamOptimizer(learning_rate=lr_init)\n","train_loss = vnet.losses['rd_loss']\n","RD_train = optimizer.minimize(train_loss, var_list = RD_var)\n","\n","with tf.Session() as sess:\n","\tinit = tf.global_variables_initializer()\n","\tsess.run(init)\n","\tsaver_res.restore(sess, res_path)\n","\n","\tt = 0.0\n","\trd_loss = 0.0\n","\tacc = 0.0\n","\tfor r in range(N_round):\n","\t\tfor roidb_id in range(N_train):\n","\t\t\troidb_use = train_roidb[roidb_id]\n","\t\t\tif len(roidb_use['rela_gt']) == 0:\n","\t\t\t\tcontinue\n","\t\t\trd_loss_temp, acc_temp = vnet.train_predicate(sess, roidb_use, RD_train)\n","\t\t\trd_loss = rd_loss + rd_loss_temp\n","\t\t\tacc = acc + acc_temp\n","\t\t\tt = t + 1.0\n","\t\t\tif t % N_show == 0:\n","\t\t\t\tprint(\"t: {0}, rd_loss: {1}, acc: {2}\".format(t, rd_loss/N_show, acc/N_show))\n","\t\t\t\trd_loss = 0.0\n","\t\t\t\tacc = 0.0\n","\t\t\tif t % N_save == 0:\n","\t\t\t\tsave_path = cfg.DIR + 'vtranse/pred_para/vrd_vgg/vrd_vgg' + format(int(t/N_save),'04') + '.ckpt'\n","\t\t\t\tprint(\"saving model to {0}\".format(save_path))\n","\t\t\t\tsaver.save(sess, save_path)\n","\t\t\t\trd_loss_val = 0.0\n","\t\t\t\tacc_val = 0.0\n","\t\t\t\tfor val_id in range(N_val):\n","\t\t\t\t\troidb_use = test_roidb[val_id]\n","\t\t\t\t\tif len(roidb_use['rela_gt']) == 0:\n","\t\t\t\t\t\tcontinue\n","\t\t\t\t\trd_loss_temp, acc_temp = vnet.val_predicate(sess, roidb_use)\n","\t\t\t\t\trd_loss_val = rd_loss_val + rd_loss_temp\n","\t\t\t\t\tacc_val = acc_val + acc_temp\n","\t\t\t\tprint(\"val: rd_loss: {0}, acc: {1}\".format(rd_loss_val/N_val, acc_val/N_val))"],"execution_count":0,"outputs":[]}]}