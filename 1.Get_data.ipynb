{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1.Get_data.ipynb","provenance":[],"authorship_tag":"ABX9TyMb9E82ijUpGTOeSpzXwgxm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1L8eanLcsK55","colab_type":"code","colab":{}},"source":["import logging\n","import csv\n","import json\n","import sys, os, time, glob\n","import pandas as pd\n","import requests, urllib, subprocess, wget\n","from dateutil.relativedelta import relativedelta\n","from persiantools.jdatetime import JalaliDate\n","import datetime\n","#___________________________________________________________________________________________________\n","logging.basicConfig(format = ' %(asctime)s  -  %(message)s')\n","logging.disable(level = logging.DEBUG)\n","\n","Paye_Farabourse = \"https://www.sahamyab.com/api/proxy/symbol/stockWatch?v=0.1&namad=&market=4&type=&sector=&page=0&pageSize=2000&sort=&\"\n","Farabourse = \"https://www.sahamyab.com/api/proxy/symbol/stockWatch?v=0.1&namad=&market=2&type=&sector=&page=0&pageSize=2000&sort=&\"\n","Bourse = \"https://www.sahamyab.com/api/proxy/symbol/stockWatch?v=0.1&namad=&market=1&type=&sector=&page=0&pageSize=2000&sort=&\"\n","\n","links = [Bourse, Farabourse, Paye_Farabourse]\n","linksName = [\"Bourse\", \"Farabourse\", \"Paye_Farabourse\"]\n","\n","stock_data_service_providers_with_bURL = {\"sahamyab\": \"https://www.sahamyab.com/guest/tradingview/history?adjustment=&\",\n","                                          \"orshan\": \"https://www.nahayatnegar.com/tv/chart/history?\",\n","                                          \"tsetmc\": \"http://www.tsetmc.com/tsev2/data/Export-txt.aspx?t=i&a=1&b=0&i=\"}\n","\n","keys = ['id', 'InsCode', 'type', 'pushId', 'name', 'title', 'corpName', 'sectionName', 'subSectionName',\n","        'status', 'date', 'q_status', 'tradeCount', 'tradeVolume', 'tradeTotalPrice', 'maxPrice',\n","        'minPrice', 'firstPrice', 'closingPrice', 'lastPrice', 'yesterdayPrice',\n","        'sellCountInd', 'sellCountCorp', 'sellVolumeInd', 'sellVolumeCorp', 'buyCountInd',\n","        'buyCountCorp', 'buyVolumeInd', 'buyVolumeCorp', 'market', 'baseVolume', 'marketValue',\n","        'totalCount', 'minAllowPrice', 'maxAllowPrice', 'minAllowVolume', 'maxAllowVolume',\n","        'estimatedEPS', 'PE', 'sectorPE', 'insCode', 'description', 'namad',\n","        'flow', 'sector', 'subsector', 'tradeDate', 'price', 'tradeValue', 'priceChange',\n","        'priceChangeClosing', 'indCount', 'indVolume', 'indValue', 'corpCount', 'corpVolume',\n","        'corpValue', 'priceChange_1', 'priceChange_7', 'priceChange_30', 'priceChange_91', 'priceChange_182',\n","        'priceChange_365']\n","\n","stockInfoCol = [\"t\", \"o\", \"h\", \"l\", \"c\", \"v\"]\n","columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n","\n","#___________________________________________*Get Stocks Json files*________________________________________________________\n","class StockDataCatcher():\n","    def __init__(self, url, monthBefor, fromDate, toDate=time.time(), resolution=\"D\"):\n","        self.url = url\n","        self.monthBefor = monthBefor\n","        self.fromDate = fromDate\n","        self.toDate = toDate\n","        self.resolution = resolution\n","    \n","    def pastDate(self, month):\n","        time = datetime.datetime.now()\n","        month_count = month\n","        relative_month = time - relativedelta(months=month_count)\n","        relative_month_timestamp = datetime.datetime.timestamp(relative_month)\n","        return relative_month_timestamp\n","\n","    def getAllStockTickerData(self, stockTicker):\n","        from_date = int(self.pastDate(self.monthBefor))\n","        to_date = int(self.pastDate(0))\n","        url =  self.url+\"symbol=\" + str(stockTicker) + \"&resolution=\" + str(self.resolution) + \"&from=\" + str(from_date) + \"&to=\" + str(to_date)\n","        data = requests.get(url=str(url))\n","        json_file = data.json()\n","        return json_file\n","\n","#_____________________________________*Get companies Json files*______________________________________________________________\n","class CompaniesDataCatcher():\n","    def __init__(self,url):\n","        self.url = url\n","\n","    def getCompanies(self):\n","        data = requests.get(url=str(self.url))\n","        json_file = data.json()\n","        return json_file\n","\n","#_____________________________________*companies files*______________________________________________________________\n","class DataWrangler():\n","    def __init__(self, jsonData, defualtDataFormat=\"csv\", isStockData=True):\n","        self.defualtDataFormat = defualtDataFormat\n","        self.jsonData = jsonData\n","        self.isStockData = isStockData\n","\n","    def saveJson(self, dirName, disFileName, disParrentDir=os.getcwd()):\n","        #_________________________create Stock Data csv\n","        if self.isStockData:\n","            if not os.path.exists(disParrentDir+\"/\"+dirName):\n","                os.makedirs(disParrentDir+\"/\"+dirName)\n","\n","            path = disParrentDir + \"/\" + dirName\n","            os.chdir(path)\n","            df = pd.DataFrame(columns=columns)\n","\n","            for i in range(0,len(self.jsonData)-1):\n","                if stockInfoCol[i] == \"t\":\n","                    strTimeStampList = self.jsonData[str(stockInfoCol[i])]\n","                    jalaliTimeStamp = []\n","                    for time in strTimeStampList:\n","                        t = JalaliDate.fromtimestamp(int(time)).strftime(\"%Y/%m/%d\")\n","                        jalaliTimeStamp.append(t)\n","                    df[columns[i]] = jalaliTimeStamp\n","                else:\n","                    df[columns[i]] = self.jsonData[str(stockInfoCol[i])]\n","            file_name = \"{}.csv\".format(disFileName)\n","            df.to_csv(file_name, encoding='utf-8')\n","        #_________________________________create Company Data csv\n","        else:\n","            if not os.path.exists(disParrentDir+\"/\"+dirName):\n","                os.makedirs(disParrentDir+\"/\"+dirName)\n","\n","            path = disParrentDir+\"/\"+dirName\n","            os.chdir(path)\n","            json = self.jsonData['items']\n","            df = pd.DataFrame(columns=keys)\n","\n","            for index, companyInfo in enumerate(json):\n","                tempDic = {}\n","                for key in keys:\n","                    nestedDic = {key:companyInfo[key]}\n","                    tempDic.update(nestedDic)\n","                df = df.append(tempDic , ignore_index=True)\n","            \n","            file_name = \"{}.csv\".format(disFileName)\n","            df.to_csv(file_name, encoding='utf-8')\n","\n","#_____________________________________data links__________________________________________________________\n","def getData(serviceProviderName, startAtMonthAgo):\n","    companyJsonData = []\n","    #_____________create companies files\n","    for indexI,link in enumerate(links):\n","        print(\"Creating {0} Companies Files ... \".format(linksName[indexI]) )\n","        companies = CompaniesDataCatcher(link)\n","        companyJsonData.append(companies.getCompanies())\n","        currentDir = os.getcwd()\n","        wrangler = DataWrangler(jsonData=companyJsonData[indexI], isStockData = False)\n","        wrangler.saveJson(disParrentDir=os.getcwd(), dirName=\"companies/\", disFileName=str(linksName[indexI]))\n","        os.chdir(currentDir)\n","\n","    print(\"Companies Files Created!\\n\")\n","    curDir = os.getcwd()\n","\n","    #_____________create StockData files\n","    for index,link in enumerate(linksName):\n","        print(\"__________Stocks Data for {0} Companies _________\".format(linksName[index]))\n","        i = 0\n","        for stockTicker in companyJsonData[index]['items']:\n","            i += 1\n","            print(\"{0} Stock Data [{1} / {2}] \".format(linksName[index] , i, len(companyJsonData[index]['items'])))\n","            stockData = StockDataCatcher(stock_data_service_providers_with_bURL[serviceProviderName], startAtMonthAgo,time.time(), time.time())\n","            json = stockData.getAllStockTickerData(stockTicker=stockTicker['name'])\n","            if json['s'] != \"no_data\":\n","                wrangler = DataWrangler(jsonData=json, isStockData=True)\n","                wrangler.saveJson(disParrentDir=os.getcwd(), dirName=\"StockData/{}/\".format(str(linksName[index])),disFileName=str(stockTicker['id']))\n","            os.chdir(curDir)\n","#________________________________________________________________________________________________________________\n","def main():\n","    getData(serviceProviderName='sahamyab', startAtMonthAgo=1)#serviceProviderName:'sahamyab','orshan','tsetmc'\n","\n","if __name__ == '__main__':\n","        main()\n"],"execution_count":0,"outputs":[]}]}